#!/usr/bin/env python3
"""
Exemplo de integraÃ§Ã£o do analisador de datasets com o AnalysisEngine.

Este script demonstra como o analisador de datasets melhora a geraÃ§Ã£o
de consultas SQL atravÃ©s da detecÃ§Ã£o automÃ¡tica de estrutura e relacionamentos.
"""

import os
import pandas as pd
import logging
from pprint import pprint

from core_integration import AnalysisEngine, Dataset
from utils.dataset_analyzer import DatasetAnalyzer

# ConfiguraÃ§Ã£o de logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

def main():
    print("\n" + "="*70)
    print("ğŸ” Sistema de Consulta Aprimorado com AnÃ¡lise DinÃ¢mica de Datasets")
    print("="*70)
    
    # Detecta credenciais de API para LLM (OpenAI ou Anthropic)
    openai_key = os.environ.get("OPENAI_API_KEY")
    anthropic_key = os.environ.get("ANTHROPIC_API_KEY")
    
    print("\nğŸ”‘ Inicializando motor de anÃ¡lise...")
    if openai_key:
        model_type = "openai"
        model_name = "gpt-3.5-turbo"
        api_key = openai_key
        print("  ğŸ”‘ Chave OpenAI encontrada. Usando modelo GPT-3.5.")
    elif anthropic_key:
        model_type = "anthropic"
        model_name = "claude-3-haiku-20240307"
        api_key = anthropic_key
        print("  ğŸ”‘ Chave Anthropic encontrada. Usando modelo Claude Haiku.")
    else:
        model_type = "mock"
        model_name = None
        api_key = None
        print("  â„¹ï¸ Nenhuma chave de API encontrada. Usando modo simulado.")
    
    # Inicializa o motor de anÃ¡lise
    engine = AnalysisEngine(
        agent_description="Assistente de AnÃ¡lise de Dados Inteligente com DetecÃ§Ã£o AutomÃ¡tica de Estrutura",
        default_output_type="dataframe",
        direct_sql=False,
        model_type=model_type,
        model_name=model_name,
        api_key=api_key
    )
    
    # Carrega datasets de exemplo
    print("\nğŸ“Š Carregando datasets...")
    dados_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), "dados")
    
    # Carrega o dataset de vendas
    vendas_path = os.path.join(dados_dir, "vendas.csv")
    engine.load_data(vendas_path, "vendas", "Registro de vendas com data, valor e cliente")
    print("  âœ… Dataset 'vendas' carregado com sucesso")
    
    # Carrega o dataset de clientes
    clientes_path = os.path.join(dados_dir, "clientes.csv")
    engine.load_data(clientes_path, "clientes", "Cadastro de clientes com nome e localizaÃ§Ã£o")
    print("  âœ… Dataset 'clientes' carregado com sucesso")
    
    # Carrega o dataset de vendas perdidas
    vendas_perdidas_path = os.path.join(dados_dir, "vendas_perdidas.csv")
    engine.load_data(vendas_perdidas_path, "vendas_perdidas", "Registro de oportunidades de vendas perdidas e seus motivos")
    print("  âœ… Dataset 'vendas_perdidas' carregado com sucesso")
    
    # Exibe informaÃ§Ãµes sobre os datasets e relacionamentos detectados
    print("\nğŸ“‹ Datasets disponÃ­veis:", ", ".join(engine.list_datasets()))
    
    # Exibe metadados detectados
    print("\nğŸ” Metadados detectados automaticamente:")
    for name in engine.list_datasets():
        dataset = engine.get_dataset(name)
        print(f"\n  ğŸ“Š Dataset: {name}")
        print(f"    â€¢ DescriÃ§Ã£o: {dataset.description}")
        print(f"    â€¢ Registros: {len(dataset.dataframe)}")
        
        if dataset.primary_key:
            print(f"    â€¢ Chave PrimÃ¡ria: {dataset.primary_key}")
        
        if dataset.potential_foreign_keys:
            print(f"    â€¢ Chaves Estrangeiras Potenciais: {', '.join(dataset.potential_foreign_keys)}")
        
        # Exibe tipos de colunas detectados
        if hasattr(dataset, 'column_types') and dataset.column_types:
            print("    â€¢ Tipos de colunas detectados:")
            for col, col_type in dataset.column_types.items():
                # Marca se for chave primÃ¡ria ou estrangeira
                suffix = ""
                if col == dataset.primary_key:
                    suffix = " (Chave PrimÃ¡ria)"
                elif col in dataset.potential_foreign_keys:
                    suffix = " (Chave Estrangeira)"
                
                print(f"      - {col}: {col_type}{suffix}")
    
    # Exibe relacionamentos detectados
    print("\nğŸ”— Relacionamentos detectados:")
    relationships_found = False
    
    for name, dataset in engine.datasets.items():
        if hasattr(dataset, 'analyzed_metadata') and dataset.analyzed_metadata:
            if 'relationships' in dataset.analyzed_metadata:
                rel_info = dataset.analyzed_metadata['relationships']
                
                # RelaÃ§Ãµes outgoing
                if 'outgoing' in rel_info and rel_info['outgoing']:
                    relationships_found = True
                    for rel in rel_info['outgoing']:
                        print(f"  â€¢ {name}.{rel['source_column']} â†’ {rel['target_dataset']}.{rel['target_column']}")
    
    if not relationships_found:
        print("  Nenhum relacionamento detectado automaticamente.")
    
    # DemonstraÃ§Ã£o do motor de consulta
    print("\nğŸ”„ Processando consultas de exemplo...")
    
    # Lista de consultas para testar
    queries = [
        "Qual Ã© o total de vendas por cliente?",
        "Quais sÃ£o os 3 principais motivos de vendas perdidas?",
        "Qual Ã© o valor mÃ©dio de vendas?",
        "Mostre os clientes de SÃ£o Paulo",
        "Liste todas as vendas do cliente JoÃ£o Silva"
    ]
    
    # Processa cada consulta
    for i, query in enumerate(queries, 1):
        print(f"\n--------- Consulta {i} ---------")
        print(f"ğŸ“ Consulta: {query}")
        
        # Processa a consulta
        response = engine.process_query(query)
        
        # Exibe o tipo de resposta
        print(f"ğŸ”„ Tipo de resposta: {response.type}")
        
        # Exibe o resultado baseado no tipo
        if response.type == "dataframe":
            # Limita a exibiÃ§Ã£o para datasets grandes
            df = response.value
            max_rows = 5
            print(f"ğŸ“Š Resultado ({min(len(df), max_rows)} linhas):")
            print(df.head(max_rows))
        elif response.type == "number":
            print(f"ğŸ”¢ Resultado numÃ©rico: {response.value}")
        elif response.type == "string":
            print(f"ğŸ“ Resultado textual: {response.value}")
        elif response.type == "plot":
            print(f"ğŸ“ˆ VisualizaÃ§Ã£o gerada: {response.value}")
        elif response.type == "error":
            print(f"âŒ Erro: {response.value}")
        
        print("-" * 30)
    
    # Modo interativo opcional
    print("\nğŸ’¬ Modo interativo. Digite 'sair' para encerrar.")
    while True:
        user_query = input("\nDigite sua consulta: ")
        if user_query.lower() in ['sair', 'exit', 'quit']:
            break
            
        # Processa a consulta do usuÃ¡rio
        response = engine.process_query(user_query)
        
        # Exibe o tipo de resposta
        print(f"ğŸ”„ Tipo de resposta: {response.type}")
        
        # Exibe o resultado baseado no tipo
        if response.type == "dataframe":
            # Limita a exibiÃ§Ã£o para datasets grandes
            df = response.value
            max_rows = 5
            print(f"ğŸ“Š Resultado ({min(len(df), max_rows)} linhas):")
            print(df.head(max_rows))
        elif response.type == "number":
            print(f"ğŸ”¢ Resultado numÃ©rico: {response.value}")
        elif response.type == "string":
            print(f"ğŸ“ Resultado textual: {response.value}")
        elif response.type == "plot":
            print(f"ğŸ“ˆ VisualizaÃ§Ã£o gerada: {response.value}")
        elif response.type == "error":
            print(f"âŒ Erro: {response.value}")

if __name__ == "__main__":
    main()